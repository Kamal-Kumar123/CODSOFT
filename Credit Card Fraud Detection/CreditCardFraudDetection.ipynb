{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27aFmUGVERpJ"
      },
      "outputs": [],
      "source": [
        "# importing the libraries needed\n",
        "import pandas as pd     #for importing data in code\n",
        "import numpy as np      #used when we want to see our data in form of array\n",
        "from sklearn.model_selection import train_test_split    #it is used to seperate train test data for using in model if we have only dataset not train and test seperately\n",
        "from sklearn.preprocessing import StandardScaler    #for data preprocessing\n",
        "from sklearn.linear_model import LogisticRegression   #here we used a model\n",
        "from sklearn.tree import DecisionTreeClassifier     #here is also a model\n",
        "from sklearn.ensemble import RandomForestClassifier     #here is also a model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score     #they are some statistics related calculation libraries\n",
        "import matplotlib.pyplot as plt      #for plotting graph and analyzing data in dataset\n",
        "import seaborn as sns          #for plotting graph clearly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "df = pd.read_csv('/content/fraudTrain.csv')    #importing data in this file\n",
        "df1 = pd.read_csv('/content/fraudTest.csv')     #importin data in this file\n",
        "\n",
        "\n",
        "# Explore the data\n",
        "# print(df.head())\n",
        "print(df['is_fraud'].value_counts())     #here we count number of unique entities and its quantity\n",
        "print(df1['is_fraud'].value_counts())\n",
        "print(df.columns)    #printing number of columns of df or data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEBZJ3JTEqey",
        "outputId": "e0d4a74b-fe45-417a-c54f-1012e04329e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is_fraud\n",
            "0    1289169\n",
            "1       7506\n",
            "Name: count, dtype: int64\n",
            "is_fraud\n",
            "0    553574\n",
            "1      2145\n",
            "Name: count, dtype: int64\n",
            "Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
            "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
            "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
            "       'merch_lat', 'merch_long', 'is_fraud'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "# check for missing values\n",
        "print(df.isnull().sum())    #number of missing values in different columns\n",
        "print(df1.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ewgK7xPEqg4",
        "outputId": "0cb4f775-3de4-411f-e5b6-0abb1dceb92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0               0\n",
            "trans_date_trans_time    0\n",
            "cc_num                   0\n",
            "merchant                 0\n",
            "category                 0\n",
            "amt                      0\n",
            "first                    0\n",
            "last                     0\n",
            "gender                   0\n",
            "street                   0\n",
            "city                     0\n",
            "state                    0\n",
            "zip                      0\n",
            "lat                      0\n",
            "long                     0\n",
            "city_pop                 0\n",
            "job                      0\n",
            "dob                      0\n",
            "trans_num                0\n",
            "unix_time                0\n",
            "merch_lat                0\n",
            "merch_long               0\n",
            "is_fraud                 0\n",
            "dtype: int64\n",
            "Unnamed: 0               0\n",
            "trans_date_trans_time    0\n",
            "cc_num                   0\n",
            "merchant                 0\n",
            "category                 0\n",
            "amt                      0\n",
            "first                    0\n",
            "last                     0\n",
            "gender                   0\n",
            "street                   0\n",
            "city                     0\n",
            "state                    0\n",
            "zip                      0\n",
            "lat                      0\n",
            "long                     0\n",
            "city_pop                 0\n",
            "job                      0\n",
            "dob                      0\n",
            "trans_num                0\n",
            "unix_time                0\n",
            "merch_lat                0\n",
            "merch_long               0\n",
            "is_fraud                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the amount feature\n",
        "# scaler = StandardScaler()\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Drop target and 'Time' column from features\n",
        "features = df.drop(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state',\n",
        "                    'zip', 'job', 'dob', 'trans_num', 'unix_time', 'is_fraud'], axis=1)\n",
        "features1= df1.drop(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state',\n",
        "                    'zip', 'job', 'dob', 'trans_num', 'unix_time', 'is_fraud'], axis=1)\n",
        "\n",
        "#here just above we drop some columns and remaining columns are saved into features variable\n",
        "\n",
        "print(features.shape[1])    #it is very basic\n",
        "print(features)\n",
        "\n",
        "# Apply StandardScaler to all features\n",
        "scaler = StandardScaler()    #here we use some scaling techniques of columns that contained by features\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "features_scaled1 = scaler.fit_transform(features1)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "df_scaled = pd.DataFrame(features_scaled, columns=features.columns)          #here we save our featured scale data to df_scaled\n",
        "df_scaled1 = pd.DataFrame(features_scaled1, columns=features1.columns)\n",
        "# Add the columns back or add some columns that are nessasary that first we removed because we don't want scaling of these columns\n",
        "df_scaled['Unnamed: 0'] = df['Unnamed: 0']\n",
        "\n",
        "df_scaled['zip'] = df['zip']\n",
        "\n",
        "df_scaled['unix_time'] = df['unix_time']\n",
        "df_scaled['is_fraud'] = df['is_fraud']\n",
        "\n",
        "\n",
        "df_scaled1['Unnamed: 0'] = df1['Unnamed: 0']\n",
        "\n",
        "df_scaled1['zip'] = df1['zip']\n",
        "\n",
        "df_scaled1['unix_time'] = df1['unix_time']\n",
        "df_scaled1['is_fraud'] = df1['is_fraud']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the data\n",
        "X_train = df_scaled.drop('is_fraud', axis=1)   #here we drop is_fraud because by this we can make our data for training purpose\n",
        "y_train = df_scaled['is_fraud']    #it is output for training purpose\n",
        "X_test = df_scaled1.drop('is_fraud', axis=1)     #it is input for test purpose\n",
        "y_test = df_scaled1['is_fraud']     #it is real output for test purpose\n",
        "\n",
        "# print(X_train.shape, y_train.shape)\n",
        "print(df_scaled.dtypes)   #here we want to see which column is of which datatype overall\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qee5klAhEqjG",
        "outputId": "9226c7b7-a77e-460a-b535-abf0c438af11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "            amt      lat      long  city_pop  merch_lat  merch_long\n",
            "0          4.97  36.0788  -81.1781      3495  36.011293  -82.048315\n",
            "1        107.23  48.8878 -118.2105       149  49.159047 -118.186462\n",
            "2        220.11  42.1808 -112.2620      4154  43.150704 -112.154481\n",
            "3         45.00  46.2306 -112.1138      1939  47.034331 -112.561071\n",
            "4         41.96  38.4207  -79.4629        99  38.674999  -78.632459\n",
            "...         ...      ...       ...       ...        ...         ...\n",
            "1296670   15.56  37.7175 -112.4777       258  36.841266 -111.690765\n",
            "1296671   51.70  39.2667  -77.5101       100  38.906881  -78.246528\n",
            "1296672  105.93  32.9396 -105.8189       899  33.619513 -105.130529\n",
            "1296673   74.90  43.3526 -102.5411      1126  42.788940 -103.241160\n",
            "1296674    4.30  45.8433 -113.8748       218  46.565983 -114.186110\n",
            "\n",
            "[1296675 rows x 6 columns]\n",
            "amt           float64\n",
            "lat           float64\n",
            "long          float64\n",
            "city_pop      float64\n",
            "merch_lat     float64\n",
            "merch_long    float64\n",
            "Unnamed: 0      int64\n",
            "zip             int64\n",
            "unix_time       int64\n",
            "is_fraud        int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(max_iter=1000)  #use of classifier\n",
        "lr.fit(X_train, y_train)    #provide training data for classifier\n",
        "y_pred_lr = lr.predict(X_test)    #provide test data for classifier\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred_lr))      #final report of output accuracy of test data"
      ],
      "metadata": {
        "id": "gUDHWadyEql3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3257155-b9b7-4021-db35-98f5ab283198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    553574\n",
            "           1       0.00      0.00      0.00      2145\n",
            "\n",
            "    accuracy                           1.00    555719\n",
            "   macro avg       0.50      0.50      0.50    555719\n",
            "weighted avg       0.99      1.00      0.99    555719\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}